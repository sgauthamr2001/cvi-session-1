{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thresholding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMylwI0qnn6SYXk5+CIt+Ow",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgauthamr2001/cvi-session-1/blob/master/Thresholding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvzMlVDsWqt6"
      },
      "source": [
        "Cloning Github repo \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWW4HtFeWqRY"
      },
      "source": [
        "!git clone https://github.com/sgauthamr2001/cvi-session-1.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_lVAFCk5LBI"
      },
      "source": [
        "Importing the necessary modules required for the task\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jljCwwDW5f9s"
      },
      "source": [
        "import cv2                         #Open-CV\n",
        "import matplotlib.pyplot as plt    #PyPlot\n",
        "import numpy as np                 #Numpy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELnY_3Jdh5Hi"
      },
      "source": [
        "Changing the directory to the one with images \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9F-4C-Ch2Nk"
      },
      "source": [
        "%cd '/content/cvi-session-1/Thresholding/src'\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "746SFKBZ6wwu"
      },
      "source": [
        "Reading an Image & Image Histogram\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "We use the function cv2.imread() to read an image. The image should be in the working directory or the full path of image should be given.\n",
        "\n",
        "cv2.imread(src, flag)\n",
        "\n",
        "Arguments  :\n",
        "\n",
        "    src – input image.\n",
        "    flag – specifies the way image should be read.\n",
        "        cv2.IMREAD_COLOR or 1: Loads a color image. Any transparency of image will be neglected. It is the default flag.\n",
        "        cv2.IMREAD_GRAYSCALE or 0 : Loads image in grayscale mode.\n",
        "\n",
        "Note:\n",
        " \n",
        "\n",
        "1.   Even if the image path is wrong, it won’t throw any error, but nothing gets stored in the image variable.\n",
        "2.   Google colab crashes if you try to display image using cv2.imshow(), which is used to display images, instead plt.imshow() is used. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK-Yv3SreB6r"
      },
      "source": [
        "deer_gray = #Fill in your code\n",
        "print(deer_gray)\n",
        "print(deer_gray.shape) \n",
        "plt.imshow(deer_gray,'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO8XO__KiuQp"
      },
      "source": [
        "The following piece of code plots the image histogram. \n",
        "\n",
        "plt.hist() is used for the same.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2fimNSVjCZG"
      },
      "source": [
        "plt.hist(deer_gray.ravel(),256,[0,255])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY-rQFOboQp6"
      },
      "source": [
        "cv2.threshold()\n",
        "\n",
        "---\n",
        "It is used for image thresholding using OpenCV\n",
        "\n",
        "\n",
        "Arguments  :\n",
        " \n",
        "    1 – Source image\n",
        "    2 – The threshold value which is used to classify the pixel values\n",
        "    3 - maxVal which represents the value to be given if pixel value is more than the threshold value\n",
        "    4 - Style of Thresholding\n",
        "\n",
        "Output :\n",
        "\n",
        "    thresh – Thresholded image\n",
        "    ret    - Threshold parameter (Only in this case) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaAV5JcOoC0V"
      },
      "source": [
        "image_gray     =  cv2.imread('apple.jpg',0)\n",
        "_,image_th     =  cv2.threshold(image_gray,225,255,cv2.THRESH_BINARY)\n",
        "_,image_th_inv =  #Fill in your code \n",
        "\n",
        "image_list  =  [image_gray,image_th,image_th_inv]\n",
        "title       =  ['Original Image','BINARY','BINARY_INV']\n",
        "for i in range(3) :\n",
        "  plt.title(title[i])\n",
        "  plt.imshow(image_list[i],'gray')\n",
        "  plt.show()\n",
        "\n",
        "image_hist = plt.hist(image_gray.ravel(),256,[0,255])\n",
        "plt.title('Image Histogram')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id9UH2F2yofo"
      },
      "source": [
        "p-Tile Thresholding \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "For p-tile thresholding, there isn't inbuilt function in OpenCV, so the following code based on the afore mentioned algorithm does the work.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXUbrT4Iy5XU"
      },
      "source": [
        "tile_gray  =  cv2.imread('cells.jpg',0)\n",
        "tile_hist  =  plt.hist(tile_gray.ravel(),256,[0,255])\n",
        "plt.title('Image Histogram')\n",
        "plt.show()\n",
        "\n",
        "for n in range(0,255):\n",
        "  #Fill in your code \n",
        "  \n",
        "_,tile_th= cv2.threshold(tile_gray,T,255,cv2.THRESH_BINARY)\n",
        "plt.imshow(tile_gray,'gray')\n",
        "plt.title('Gray-Scale Image')\n",
        "plt.show()\n",
        "plt.imshow(tile_th,'gray')\n",
        "plt.title('Thresholded Image')\n",
        "plt.show()\n",
        "print('The threshold value is %d' % T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPS3YnLtL0wZ"
      },
      "source": [
        "Iterative Thresholding\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Further there is no function in OpenCV for Iterative Global Thresholding as well, the code for the algorithm mentioned previously is a follows : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnIpXO7SNIp5"
      },
      "source": [
        "iter_gray = cv2.imread('ball.jpg',0)\n",
        "iter_hist = plt.hist(iter_gray.ravel(),256,[0,255])\n",
        "plt.title('Image Histrogram')\n",
        "plt.show() \n",
        "\n",
        "n = np.arange(256)\n",
        "iter_hist_n = iter_hist[0]*n\n",
        "T = np.sum(iter_hist_n)/np.sum(iter_hist[0])\n",
        "print('The mean intensity of the pixels is %.2f' % T)\n",
        "\n",
        "delta = 10\n",
        "while delta > 0.5 :\n",
        "  M1    = np.sum(iter_hist_n[:int(T)-1])/np.sum(iter_hist[0][:int(T)-1])\n",
        "  M2    = #Fill in your code \n",
        "  delta = abs(T-0.5*(M1+M2))\n",
        "  T     = int((M1 + M2)/2)\n",
        "_,iter_th = cv2.threshold(iter_gray,T,255,cv2.THRESH_BINARY)\n",
        "\n",
        "plt.imshow(iter_gray,'gray')\n",
        "plt.title('Gray-Scale Image')\n",
        "plt.show()\n",
        "plt.imshow(iter_th,'gray')\n",
        "plt.title('Thresholded Image')\n",
        "plt.show()\n",
        "print('The threshold value is %d' % T)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gffcO6GjWS8e"
      },
      "source": [
        "Otsu's Binarization\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "For Otsu's Binarisation, cv2.threshold() function is used, but an extra flag, \n",
        "cv2.THRESH_OTSU is passed. For threshold value, zero is passed unlike the previous cases. The algorithm finds the optimal threshold value and returns as output. If Otsu's thresholding is not used, returned value is same as the threshold value given by the user. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcjsToAlcJo7"
      },
      "source": [
        "otsu_gray = cv2.imread('cells_otsu.jpg',0)\n",
        "otsu_hist = plt.hist(otsu_gray.ravel(),256,[0,255])\n",
        "plt.title('Image Histogram')\n",
        "plt.show()\n",
        "T,otsu_th = cv2.threshold(otsu_gray,0,255,cv2.THRESH_OTSU)\n",
        "plt.imshow(otsu_gray,'gray')\n",
        "plt.title('Gray-Scale Image')\n",
        "plt.show()\n",
        "plt.imshow(otsu_th,'gray')\n",
        "plt.title('Thresholded Image')\n",
        "plt.show()\n",
        "print('The threshold value using Otsu method is %d' % T)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdQFH5D6km5o"
      },
      "source": [
        "Adaptive Thresholding \n",
        "\n",
        "---\n",
        "cv2.adaptiveThreshold()\n",
        "\n",
        "The function has 6 input params and 1 output params.\n",
        "\n",
        "Arguments  :\n",
        " \n",
        "    1 – Source image\n",
        "    2 - maxVal which represents the value to be given if pixel value is more than the threshold value\n",
        "    3 - Style of Thresholding - \n",
        "        cv2.ADAPTIVE_THRESH_MEAN_C : Threshold value is the mean of neighbourhood area. \n",
        "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C : threshold value is the weighted sum of neighbourhood values where weights are a gaussian window.\n",
        "    4 - Thresholding Type - cv2.THRESH_BINARY\n",
        "    5 - Block size N\n",
        "    6 - Constant C\n",
        "Output :\n",
        "\n",
        "    Thresholded image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2lR-ZIVomgd"
      },
      "source": [
        "adaptive_gray = cv2.imread('sudoku.jpg',0)\n",
        "adaptive_hist = plt.hist(adaptive_gray.ravel(),256,[0,255])\n",
        "plt.title('Image Histogram')\n",
        "plt.show()\n",
        "T,otsu_th = cv2.threshold(adaptive_gray,0,255,cv2.THRESH_OTSU)\n",
        "adap_m_th = cv2.adaptiveThreshold(adaptive_gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
        "adap_g_th = #Fill in your code \n",
        "\n",
        "image_list  =  [adaptive_gray,otsu_th,adap_m_th,adap_g_th]\n",
        "title       =  ['Original Image','Otsu Binarisation','Adaptive Mean','Adaptive Gaussian']\n",
        "for i in range(4) :\n",
        "  plt.title(title[i])\n",
        "  plt.imshow(image_list[i],'gray')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4f44Ih4vK--"
      },
      "source": [
        "Take-home Tasks :\n",
        "\n",
        "---\n",
        "\n",
        "1.   Consider the following image 'shapes.jpg' , perform otsu's binarisation, as well as adaptive thresholding, and try analysing the difference between the thresholded images in both the cases. \n",
        "![shapes.png](data:image/png;base64,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)\n",
        "2. Try splitting the sudoku image into sub-images as done in slides and perform the global thresholding on these sub-parts. \n",
        "\n",
        "\n"
      ]
    }
  ]
}